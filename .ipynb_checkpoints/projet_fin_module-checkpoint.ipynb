{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc2bc31",
   "metadata": {},
   "source": [
    "<h1><center>Projet SES722 </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794eedcb",
   "metadata": {},
   "source": [
    "<h1><center>Guillaume CANAT & Waly NGOM </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83327d",
   "metadata": {},
   "source": [
    "<h1><center>Partie 1: Régression </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4821271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des librairies utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de5418",
   "metadata": {},
   "source": [
    "##### 1. Lire le fichier mroz.raw. Ne sélectionner que les observations pour lesquelles la variable wage est strictement positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75c382",
   "metadata": {},
   "source": [
    "Lecture du texte descriptif des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ce270d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mroz.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8n/vn4xps9n5jz32mlnf1k1t9tm0000gn/T/ipykernel_66093/2472052580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lecture du texte descritif des données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mroz.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Affichage du texte descriptif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mroz.txt'"
     ]
    }
   ],
   "source": [
    "#lecture du texte descritif des données\n",
    "f = open('mroz.txt', 'r')\n",
    "description = f.read()\n",
    "f.close;\n",
    "#Affichage du texte descriptif\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29a386",
   "metadata": {},
   "source": [
    " Lecture et affichage  le fichier mroz.raw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50494a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture du fichier \n",
    "mroz = pd.read_csv('mroz.csv',delim_whitespace=True, header=None,names=['inlf','hours','kidslt6','kidsge6',\n",
    "                'age','educ','wage','repwage','hushrs','husage','huseduc','huswage','faminc','mtr','motheduc',  \n",
    "                 'fatheduc','unem','city','exper','nwifeinc','lwage','expersq'])   \n",
    "\n",
    "mroz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information sur les données\n",
    "mroz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a22799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacement des points par des zeros\n",
    "mroz['wage']=mroz['wage'].replace('.','0')\n",
    "mroz['lwage']=mroz['lwage'].replace('.','0')\n",
    "mroz['wage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4f027",
   "metadata": {},
   "source": [
    "Sélection des observations pour lesquelles la variable wage est strictement positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertion des valeurs de la variable 'wage' en float (nombre à virgule)\n",
    "mroz['wage']=mroz['wage'].astype(float)\n",
    "mroz['lwage']=mroz['lwage'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746110f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sélection des observations pour lesquelles la variable wage est strictement positive\n",
    "mroz=mroz[mroz['wage']>0]\n",
    "mroz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c94206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification des informations du nouveau dataset\n",
    "mroz.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2995f",
   "metadata": {},
   "source": [
    "##### 2. Faire les statistiques descriptives du salaire, de l’age et de l’éducation pour l’ensemble des femmes puis, pour les femmes dont le salaire du mari est supérieure au 65ème percentile de l’échantillon, puis pour les femmes dont le salaire du mari est inférieur au 65ème percentile de l’échantillon. Commenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistique descriptive du salaire, de l'âge et de l'éducation pour l'ensemble des femmes\n",
    "WaeFemme = mroz[['wage','age','educ']]\n",
    "WaeFemme.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul du 65eme perceptile du salaire des hommes\n",
    "percentile_65 =np.percentile(mroz['huswage'], 65)\n",
    "percentile_65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74447fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Statistique descriptive du salaire, de l'âge et de l'éducation pour des femmes\n",
    "#dont le salaire du mari est supérieur au 65eme perceptile\n",
    "Waefemmesup=(WaeFemme.loc[mroz['huswage'] > percentile_65])\n",
    "Waefemmesup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ba3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Statistique descriptive du salaire, de l'âge et de l'éducation pour des femmes\n",
    "#dont le salaire du mari est inferieur au 65eme perceptile\n",
    "Waefemmesup=(WaeFemme.loc[mroz['huswage'] <= percentile_65])\n",
    "Waefemmesup.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74324dc",
   "metadata": {},
   "source": [
    "##### Commentaires:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0d8a6",
   "metadata": {},
   "source": [
    "Le salaire moyen (et médian) des femmes dont les maris ont un salaire inférieur au 65ème percentile est inférieur à celui des  autre femmes.\n",
    "\n",
    "L'écart-type du salaire des femmes dont le mari à un salaire supérieur au 65ème percentile est plus important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30f1b0",
   "metadata": {},
   "source": [
    "##### 3. Faire l'histogramme de la variable wage. Supprimer les observations qui sont à plus de 3 écart-types de la moyenne et refaire l’histogramme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac71525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramme de la variable wage\n",
    "salaire=mroz['wage']\n",
    "plt.hist(salaire)\n",
    "plt.show();\n",
    "salaire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecartype=np.std(mroz['wage'])\n",
    "moyenne = np.mean(mroz[\"wage\"])\n",
    "borneinf = moyenne-(3*ecartype)\n",
    "bornesup = moyenne+(3*ecartype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaire.drop(salaire[(mroz[\"wage\"]<borneinf) | (mroz[\"wage\"]>bornesup)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a995a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramme de la variable wage\n",
    "plt.hist(salaire)\n",
    "plt.show();\n",
    "salaire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b90c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f92bad",
   "metadata": {},
   "source": [
    "##### 4. Calculer les corrélations motheduc et fatheduc. Expliquer le problème de multi-collinéarité. Commenter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(mroz['motheduc'],mroz['fatheduc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc678c8",
   "metadata": {},
   "source": [
    "Le coefficient de correlation linéaire entre 'motheduc' et 'fatheduc' et de $0.5487$ environ.\n",
    "\n",
    "Problème de la multi-colinéairité: si des variables sont colinéaires alors la matrice X n'est pas de plein rang et donc pas inversible. On aura donc pas de solution unique pour les paramètres du modèle.\n",
    "\n",
    "Commentaires:Il se posera aussi un problème sur le calcul de la variance des estimateurs ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892634e3",
   "metadata": {},
   "source": [
    "##### 5. Faites un graphique en nuage de point entre wage et educ,. S'agit-il d'un effet \"toute chose étant égale par ailleurs ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc05efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(mroz[\"educ\"], mroz[\"wage\"],  marker='+')\n",
    "plt.title(\"Nuage de points entre les variables 'wage' et 'educ'\")\n",
    "plt.xlabel(\"educ\")\n",
    "plt.ylabel(\"wage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d69d3",
   "metadata": {},
   "source": [
    "Commentaire : Pour pouvoir extraire de l'information de ce type graphique, on doit en effet supposer toute chose égale par ailleurs, cependant on voit bien que ça n'est pas le cas ici puisque pour une valeur d'educ on peut avoir de nombreuses valeurs de wage très disparates (comme par exemple pour educ = 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ffd3f",
   "metadata": {},
   "source": [
    "##### 6. Quelle est l'hypothèse fondamentale qui garantit des estimateurs non biaisés ?  Expliquer le biais de variable omise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297214e",
   "metadata": {},
   "source": [
    "L’hypothèse fondamentale garantissant des estimateurs non biaisés:\n",
    "\n",
    "1. Les variables non observées $\\varepsilon$ sont de moyenne nulle i.e $ \\mathbb{E}(\\varepsilon)=0$.\n",
    "\n",
    "2. Les variables observées $X$ et les variables non observées $\\varepsilon$ sont non corrélées i.e $\\mathbb{E}(\\varepsilon|x)= 0.$\n",
    "\n",
    "3. La matrice $X$ est de plein rang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f05c2",
   "metadata": {},
   "source": [
    "Explication de la variable omise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf22eea",
   "metadata": {},
   "source": [
    "On parle de biais de variable omise lorsqu’une des variables explicatives (une composante de X) corrélée à la fois avec la variable expliquée et avec le terme d’erreur n’est pas prise en compte dans l’équation. Dans ce cas, l’hypothèse fondamentale garantissant que les estimateurs MCO sont non biaisés n’est plus valide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255e632",
   "metadata": {},
   "source": [
    "##### 7. Faire la régression du log de wage en utilisant comme variables explicatives une constante, city, educ, exper, nwifeinc, kidslt6, kidsgt6. Commentez l'histogramme des résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd90cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression de wage en utilisant comme variables explicatives \n",
    "#une constante, city, educ, exper, nwifeinc, kidslt6, kidsgt6\n",
    "y=mroz['lwage']\n",
    "X = sm.add_constant(mroz[['city', 'educ', 'exper', 'nwifeinc', 'kidslt6', 'kidsge6']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sm.OLS(y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cf0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultats.summary())\n",
    "u=resultats.resid\n",
    "SSR0=u.T@u\n",
    "print(SSR0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d124c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogramme des résidus\n",
    "plt.figure(figsize=(11, 7))\n",
    "sns.distplot(u)\n",
    "plt.title(\"Hitogramme des résidus du modèle\", fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62685079",
   "metadata": {},
   "source": [
    "Commentaire : la distribution des résidus a une forme quasi-gaussienne bien que l'on note une légère disymmétrie (skewness) et \"longue queue\" à gauche (kurtosis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e74e81",
   "metadata": {},
   "source": [
    "#### 8. Tester l'hypothèse de non significativité de nwifeinc avec un seuil de significativité de 1%, 5% et 10% (test alternatif des deux côtés). Commentez les p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8848dd",
   "metadata": {},
   "source": [
    "Nous faisons ici le test de Student pour le $k-ième$ paramètre $\\beta_k= nwifeinc$ On a:\n",
    "\n",
    "\n",
    "- estimateur de $\\sigma^2$ : $\\hat{\\sigma}^2 = \\frac{1}{n-p-1}\\|Y - X \\beta\\|^2$, avec $n$ le nombre d'observations et $p+1$ le rang de $X$ (constante inclue),\n",
    "\n",
    " - $\\hat{s}_k^2$ = $n (X^TX)^{-1}_{k,k}$ , le $k$-ième élément de la diagonale\n",
    "\n",
    " - alors\n",
    "$$T = \\sqrt \\frac{n}{\\hat{s}_k^2 \\hat{\\sigma}^2_{k}}(\\hat{\\beta}_{k} - \\beta^{*}_{k}) \\sim \\mathcal{T}_{n-p-1}$$\n",
    "\n",
    "Hypothèse nulle : $\\beta^{*}_{k}=0$. On a donc la statistique de test suivante :\n",
    "$$T = \\sqrt \\frac{n}{\\hat{s}_k^2 \\hat{\\sigma}^2_{k}}\\hat{\\beta}_{k} \\sim \\mathcal{T}_{n-p-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X.shape\n",
    "\n",
    "gram = X.T.dot(X) / n\n",
    "\n",
    "sigma_hat = np.sqrt(np.sum(u**2) / (n - p))\n",
    "teta_nwifeinc = resultats.params[\"nwifeinc\"]\n",
    "s_nk = np.sqrt(pd.DataFrame(np.linalg.inv(gram), gram.columns, gram.index).loc[\"nwifeinc\", \"nwifeinc\"])\n",
    "\n",
    "t_stat = np.sqrt(n) / (s_nk * sigma_hat) * teta_nwifeinc\n",
    "p_value = stats.t.sf(t_stat, n-p)*2\n",
    "\n",
    "pd.DataFrame({\"t-stat\": t_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'t-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce842c",
   "metadata": {},
   "source": [
    "On ne rejette pas l'hypothèse $H_0$  pour un seuil de significativité de $1\\%, \\quad 5\\%$ ou encore pour un seuil de significativité de $10\\%.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81401e84",
   "metadata": {},
   "source": [
    "##### 9.Tester l’hypothèse que le coefficient associé à nwifeinc est égal à 0.01 avec un seuil de significativité de 5% (test à alternatif des deux côtés)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d724adc",
   "metadata": {},
   "source": [
    "Nous avons ici l'hypothèse: ${\\bf \\{ \\theta_{nwifeinc} = 0.01 \\}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84231d17",
   "metadata": {},
   "source": [
    "Sous cette hypothèse, on a $ \\frac{n^{\\frac{1}{2}}}{\\hat{s}_{n,k}^{\\frac{1}{2}}\\hat{\\sigma}_n}(\\hat{\\theta}_{nwifeinc} - 0.01)\\sim \\mathcal{T}_{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat = np.sqrt(n) / (s_nk * sigma_hat) * (teta_nwifeinc - 0.01)\n",
    "p_value = stats.t.sf(np.abs(t_stat), n-p)*2\n",
    "\n",
    "pd.DataFrame({\"t-stat\": np.abs(t_stat), \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'t-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d86552",
   "metadata": {},
   "source": [
    "La p-value du test est de $0.125$, le test de significativité à $5\\%$ n’est donc pas rejetté."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86720531",
   "metadata": {},
   "source": [
    "##### 10. Tester l’hypothèse jointe que le coefficient de nwifeinc est égal à 0.01 et que celui de city est égal à 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c6ffe",
   "metadata": {},
   "source": [
    "Nous avons un modèle initial: \n",
    "\n",
    "$log(wage)= \\beta_0 + \\beta_{city}*city + \\beta_{educ}*educ + \\beta_{exper}*exper +\\beta_{nwifeinc}*nwifeinc+\n",
    "\\beta_{kidslt6}*kidslt6+\\beta_{kidsge6}*kidsge6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63765c9",
   "metadata": {},
   "source": [
    "Sous l'hyppothèse,\n",
    "\n",
    "$H_0=\\{ \\beta_{nwifeinc}=0.01 , \\beta_{city}=0.05 \\}$, nous allons appliquer le test de Fisher au modèle\n",
    "\n",
    "$log(wage)= \\beta_0 + 0.05*city + \\beta_{educ}*educ + \\beta_{exper}*exper + 0.01*nwifeinc+\n",
    "\\beta_{kidslt6}*kidslt6+\\beta_{kidsge6}*kidsge6, $ c'est à dire à:\n",
    "\n",
    "$log(wage)- 0.05*city-  0.01*nwifeinc=\\beta_0 + \\beta_{educ}*educ + \\beta_{exper}*exper +\n",
    "\\beta_{kidslt6}*kidslt6+\\beta_{kidsge6}*kidsge6.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c5df4",
   "metadata": {},
   "source": [
    "Le statistique de Fisher associée a ces deux modèles est:\n",
    "\n",
    "\n",
    "$f_{stat} = \\frac{\\frac{SSE_1-SSE}{2}}{\\frac{SSE}{n-p-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fit linear regression model with all variables --- #\n",
    "\n",
    "X = sm.add_constant(mroz[['city', 'educ', 'exper', 'nwifeinc', 'kidslt6', 'kidsge6']])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "residual = results.resid\n",
    "\n",
    "SSE = np.sum(residual**2)\n",
    "\n",
    "# --- fit regression model with 2 constraints on beta coefficients --- #\n",
    "\n",
    "X = sm.add_constant(mroz[['educ', 'exper', 'kidslt6', 'kidsge6']])\n",
    "y = mroz[\"lwage\"] - 0.05*mroz[\"city\"] - 0.01*mroz[\"nwifeinc\"]\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "residual = results.resid\n",
    "\n",
    "SSE1 = np.sum(residual**2)\n",
    "\n",
    "\n",
    "# --- Compute Fisher Stat --- #\n",
    "\n",
    "f_stat = ((SSE1 - SSE) / 2)  /  (SSE / (n - p))\n",
    "p_value = stats.f.sf(f_stat, 2, n - p)\n",
    "\n",
    "pd.DataFrame({'f-stat': f_stat, 'p-value': p_value}, index=['results'])\\\n",
    "               .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c33b9",
   "metadata": {},
   "source": [
    "La p-valeur du test est $ 0.264$, l’hypothèse $H_0=\\{ \\beta_{nwifeinc}=0.01 , \\beta_{city}=0.05 \\}$ est donc acceptée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11449a",
   "metadata": {},
   "source": [
    "##### 11. Tester l’hypothèse joint que $H_0=\\{ \\beta_{nwifeinc}+\\beta_{city}=0.1, \\beta_{educ}+\\beta_{exper}=0.1 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65622dd8",
   "metadata": {},
   "source": [
    "L'hypothèse jointe peut encore s'écrire:\n",
    "\n",
    "$$\n",
    "\\left \\{\n",
    "\\begin{array}{c c}\n",
    "    \\beta_{nwifeinc} &= 0.1- \\beta_{city} \\\\\n",
    "   \\beta_{educ} &= 0.1 -  \\beta_{exper}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3c4e5",
   "metadata": {},
   "source": [
    "Le modèle initial devient:\n",
    "\n",
    "$log(wage)= \\beta_0 + \\beta_{city}*city + {\\bf (0.1 -  \\beta_{exper})}*educ + \\beta_{exper}*exper +{\\bf (0.1- \\beta_{city})}*nwifeinc+ \\beta_{kidslt6}*kidslt6+\\beta_{kidsge6}*kidsge6$, c'est à dire :\n",
    "\n",
    "\n",
    "$log(wage)- 0.1*educ -0.1*nwifeinc= \\beta_0 + \\beta_{city}(city-nwifeinc) + \\beta_{exper}*(exper-educ)+  \\beta_{kidslt6}*kidslt6+\\beta_{kidsge6}*kidsge6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f003bfe",
   "metadata": {},
   "source": [
    "Et du coup, La statistique de Fisher associé a ces deux modèles est:\n",
    "\n",
    "\n",
    "$f_{stat} = \\frac{\\frac{SSE_1-SSE}{2}}{\\frac{SSE}{n-p-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2149c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fit linear regression model with all variables --- #\n",
    "\n",
    "X = sm.add_constant(mroz[['city', 'educ', 'exper', 'nwifeinc', 'kidslt6', 'kidsge6']])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "residual = results.resid\n",
    "\n",
    "SSE = np.sum(residual**2)\n",
    "\n",
    "# --- fit regression model with 2 constraints on beta coefficients --- #\n",
    "\n",
    "X = sm.add_constant(mroz[['kidslt6', 'kidsge6']])\n",
    "X['city_nwfeinc'] = mroz['city'] - mroz['nwifeinc']\n",
    "X['exper_educ'] =  mroz['exper'] - mroz['educ']\n",
    "y = mroz['lwage'] - 0.1*mroz['educ'] - 0.1*mroz['nwifeinc']\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "residual = results.resid\n",
    "\n",
    "SSE1 = np.sum(residual**2)\n",
    "\n",
    "\n",
    "# --- Compute Fisher Stat --- #\n",
    "\n",
    "f_stat = ((SSE1 - SSE) / 2)  /  (SSE / (n - p))\n",
    "p_value = stats.f.sf(f_stat, 2, n - p)\n",
    "\n",
    "pd.DataFrame({\"f-stat\": f_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2485b48",
   "metadata": {},
   "source": [
    "La p-valeur du test est $0.398,$ , l'hypothèse $H_0=\\{ \\beta_{nwifeinc}+\\beta_{city}=0.1, \\beta_{educ}+\\beta_{exper}=0.1 \\}$ est donc acceptée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b058e7",
   "metadata": {},
   "source": [
    "##### 12.  Faites une représentation graphique de la manière dont le salaire augmente avec l’éducation et l’expérience professionnelle. Commentez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96c965",
   "metadata": {},
   "source": [
    "Nous faisons ici:\n",
    "\n",
    "1. une représentation de wage (estimated wage from earns., hours) en fonction de  exper selon que le niveau d'éducation soit inférieur ou supérieur à la valeur médiane de la varibale \"educ\" (On peut le faire avec chaque quartile).\n",
    "\n",
    "2. une représentation de repwage (reported wage at interview in 1976) en fonction de  exper selon que le niveau d'éducation soit inférieur ou supérieur à la valeur médiane de la varibale \"educ\" .\n",
    "\n",
    "3.  une représentation (dans l'espace à trois dimensions) de wage en fonction de educ et exper.\n",
    "\n",
    "4.  une représentation (dans l'espace à trois dimensions) de repwage en fonction de educ et exper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiles = [np.percentile(mroz['huseduc'],q) for q in [0, 25, 50, 75, 100]]\n",
    "df = mroz.copy()\n",
    "df[\"educ>= quartiles[2]\"] = df.educ>= quartiles[2]\n",
    "_, axes = plt.subplots( figsize=(14, 7))\n",
    "\n",
    "with sns.plotting_context(rc={\"legend.fontsize\":11}):\n",
    "    sns.lineplot(x=\"exper\", y=\"wage\", hue=\"educ>= quartiles[2]\", data=df, ax=axes)\n",
    "    plt.xlabel(\"exper\", fontsize=11)\n",
    "    plt.ylabel(\"wage\", fontsize=11)\n",
    "    \n",
    "axes.set_title(\"Evolution du salaire/(heure travaillée) en fonction du niveau d'éducation et de l'expérience\",\n",
    "                  fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f87a44",
   "metadata": {},
   "source": [
    "a. On constate que le salaire \"wage\" est plus corrélé au niveau d'éducation qu'à l'expérience professionnelle tandis \"repwage\" est plus corrélé à l'expérience professionnelle. On peut  d'ailleurs le voir aussi en chiffres avec la matrice de covariance ci-dessous\n",
    "\n",
    "b. En debut et en fin de carrière, on constate que le niveau d'éducation a une forte influence sur le salaire\n",
    "\n",
    "c. Entre 8 ans et 13 ans d'expérience, le niveau d'éducation n'a pas beaucoup d'influence .\n",
    "\n",
    "d. Par ailleurs, pour les personnes qui ont un niveau d'éducation supérieur  à la valeur médiane de la variable \"educ\", le salaire croit fortement avec l'expérience à l'opposé des personnes ayant un niveau d'éducation inférieur à cette valeur médiane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"wage\",\"educ\",\"exper\"]].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5560e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db87cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"educ\", \"exper\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"wage\"]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "xx = np.linspace(df[\"educ\"].min(), df[\"educ\"].max(),10)\n",
    "yy = np.linspace(df[\"exper\"].min(), df[\"exper\"].max(),10)\n",
    "xx, yy = np.meshgrid(xx, yy)\n",
    "\n",
    "exog = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "exog = sm.add_constant(exog)\n",
    "\n",
    "zz = model.predict(params=results.params, exog=exog).reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.plot_surface(xx, yy, zz, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "ax.plot_wireframe(xx,yy,zz)\n",
    "ax.scatter(df[\"educ\"], df[\"exper\"], df[\"wage\"], alpha=0.7)\n",
    "ax.set_xlabel('education')\n",
    "ax.set_ylabel('experience')\n",
    "ax.set_zlabel('wage')\n",
    "ax.view_init(10, -60)\n",
    "ax.set_title(\"wage en fonction de l'experience et l'éducation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coéfficients de regression :\\n{results.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc2606",
   "metadata": {},
   "source": [
    "On peut remarquer que le coéfficient de l'hyperplan de regression est plus important sur l'axe educ que sur l'axe exper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ec279",
   "metadata": {},
   "source": [
    "##### 13. Tester l’égalité des coefficients associés aux variables kidsgt6 et kidslt6. Interprétez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940b9c7",
   "metadata": {},
   "source": [
    "Cette question revient à tester l'hypothèse ${\\bf H_0} = \\{ \\beta_{kidsgt6}= \\beta_{kidst6} \\}=\\{\\theta:= \\beta_{kidsgt6}- \\beta_{kidst6}=0 \\}.$\n",
    "\n",
    "\n",
    "Sous cette hypothèse, le modèle initial devient:\n",
    "\n",
    "$log(wage)= \\beta_0 + \\beta_{city}*city + \\beta_{educ}*educ + \\beta_{exper}*exper +\\beta_{nwifeinc}*nwifeinc+\n",
    " \\beta_{kidslt6}*(kidslt6+kidsge6)+ \\theta*kidsge6$\n",
    "\n",
    "\n",
    "\n",
    "Sous cette hypothèse, on a $ \\frac{n^{\\frac{1}{2}}}{\\hat{s}_{n,k}^{\\frac{1}{2}}\\hat{\\sigma}_n}\\hat{\\theta} \\sim \\mathcal{T}_{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(mroz[['city', 'educ', 'exper', 'nwifeinc','kidsge6']])\n",
    "X['kidslt6_kidsge6'] = mroz['kidslt6']+ mroz['kidsge6']\n",
    "n,p=X.shape\n",
    "y = mroz['lwage']\n",
    "\n",
    "lastmodel=sm.OLS(y,X)\n",
    "resultats=lastmodel.fit()\n",
    "gram = X.T.dot(X) / n\n",
    "u=resultats.resid\n",
    "sigma_hat = np.sqrt(np.sum(u**2) / (n - p))\n",
    "theta =resultats.params['kidsge6']\n",
    "s_nk = np.sqrt(pd.DataFrame(np.linalg.inv(gram), gram.columns, gram.index).loc['kidsge6', 'kidsge6'])\n",
    "\n",
    "\n",
    "t_stat = np.sqrt(n) / (s_nk * sigma_hat) * theta\n",
    "p_value = stats.t.sf(np.abs(t_stat), n-p)*2\n",
    "\n",
    "pd.DataFrame({\"t-stat\": np.abs(t_stat), \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'t-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfb04c",
   "metadata": {},
   "source": [
    "Avec cette p-value, on ne rejette donc pas l'hypothèse $H_0$ au seil de $5\\%.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946c4c3",
   "metadata": {},
   "source": [
    "On peut dire ici que l'âge des enfants ( moins de 6 ans ou entre 6 ans et 18 ans) n'aurait pas d'influence dans ce modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7d1e4",
   "metadata": {},
   "source": [
    "###### 14.  Faire le test d'hétéroscédasticité de forme linéaire en donnant la p-valeur. Déterminer la ou les sources d’hétéroscédasticité et corriger avec les méthodes vues en cours. Comparer les écarts-types des coefficients estimés avec ceux obtenus à la question 7. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64916a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test d'hétéroscédasticité\n",
    "X = sm.add_constant(mroz[['city','educ','exper','nwifeinc','kidslt6','kidsge6']])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "\n",
    "\n",
    "residual = resultats.resid\n",
    "model_heterosc = sm.OLS(residual**2, X)\n",
    "resultats_heterosc = model_heterosc.fit()\n",
    "\n",
    "SSE = np.sum(resultats_heterosc.resid**2)\n",
    "\n",
    "SSE1 = np.var(residual**2) * n\n",
    "\n",
    "# --- Compute Fisher Stat --- #\n",
    "\n",
    "f_stat = ((SSE1 - SSE) / 6)  /  (SSE / (n - p))\n",
    "p_value = stats.f.sf(f_stat, 6, n - p)\n",
    "\n",
    "pd.DataFrame({\"f-stat\": f_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "                  .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f27feb",
   "metadata": {},
   "source": [
    "On ne peut donc pas rejeter l'hypothèse d'homoscédasticité. Mais vu la p-value,il existe des sources d'héteroscédasticité.\n",
    "\n",
    "\n",
    "Observons l’hétéroscédasticité coefficient par coefficient avec un test de Student:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ad562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultats_heterosc.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6325dc3",
   "metadata": {},
   "source": [
    "On remarque que la variable exper est significative. Pour y voir plus clair, traçcons les courbes des résidus en fonction de quelques grandeurs (les coefficients et les valeurs estimées)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa84613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revoir!!!!\n",
    "X = sm.add_constant(mroz[['city','educ','exper','nwifeinc','kidslt6','kidsge6']])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "\n",
    "\n",
    "residual = resultats.resid\n",
    "mroz['y_hat']=resultats.predict(X)\n",
    "\n",
    "#y_hat = resultats.predict(X)\n",
    "abscisses= [['y_hat','city','educ'],['exper','nwifeinc','kidslt6']]\n",
    "\n",
    "_, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        sns.lineplot(x=mroz[abscisses[i][j]],y=residual,data=mroz,ax=axes[i][j])\n",
    "        plt.xlabel(abscisses[i][j], fontsize=14)\n",
    "        plt.ylabel(\"residual\", fontsize=14)\n",
    "        axes[i][j].set_title(f\"Résidus vs %s\" %abscisses[i][j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54aac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56ab6573",
   "metadata": {},
   "source": [
    "En observant les p-valeurs obtenues  coefficient par coefficient, on voit que exper est significatif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd844eb",
   "metadata": {},
   "source": [
    "Nous corrigeons l'hétéroscédasticité en enlevant les outliers (On peut aussi penser à une Weight least square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask booléen : valeur absolue de l'écart entre l'observation et la moyenne\n",
    "mroz.drop(mroz[(mroz[\"wage\"]<borneinf) | (mroz[\"wage\"]>bornesup)].index, inplace=True)\n",
    "mroz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbcc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(mroz[['city','educ','exper','nwifeinc','kidslt6','kidsge6']])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "\n",
    "\n",
    "residual = resultats.resid\n",
    "model_heterosc = sm.OLS(residual**2, X)\n",
    "resultats_heterosc = model_heterosc.fit()\n",
    "\n",
    "SSE = np.sum(resultats_heterosc.resid**2)\n",
    "\n",
    "SSE1 = np.var(residual**2) * n\n",
    "\n",
    "# --- Compute Fisher Stat --- #\n",
    "\n",
    "f_stat = ((SSE1 - SSE) / 6)  /  (SSE / (n - p))\n",
    "p_value = stats.f.sf(f_stat, 6, n - p)\n",
    "\n",
    "pd.DataFrame({\"f-stat\": f_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "                  .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultats_heterosc.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d768546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a47337ae",
   "metadata": {},
   "source": [
    "###### 15. Tester le changement de structure de la question 8 entre les femmes qui ont plus de 43 ans et les autres : test sur l'ensemble des coefficients. Donnez les p-valeurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d46592",
   "metadata": {},
   "source": [
    "Nous allons tester l'égalité de l'ensemble des coefficients sur le modèle \n",
    "\n",
    "$log(wage)= \\beta_0 + \\beta_{city}*city + \\beta_{educ}*educ + \\beta_{exper}*exper +\\beta_{nwifeinc}*nwifeinc+\n",
    " \\beta_{kidslt6}*(kidslt6+kidsge6)+ \\theta*kidsge6$\n",
    " \n",
    " pour deux groupes d'indicidus: \n",
    " \n",
    " - Le groupe dont l'âge $\\leq 43$ ans.\n",
    " \n",
    " - Le goupe dont l'âge $> 43$ ans.\n",
    " \n",
    " Nous commençons faire une regression de l'ensemble des individus puis une regression pour chaque groupe d'individus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b1b46",
   "metadata": {},
   "source": [
    "1. regression pour l'ensemble des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(mroz[[\"city\", \"educ\", \"exper\", \"nwifeinc\", \"kidslt6\", \"kidsge6\"]])\n",
    "y = mroz['lwage']\n",
    "n, p = X.shape\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "\n",
    "# Somme des carrés des residus pour l'ensemble\n",
    "SSE_ens = np.sum(resultats.resid**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bece1",
   "metadata": {},
   "source": [
    "2. Regression pour le groupe dont l'âge est $\\leq 43$ ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(mroz.loc[mroz.age <= 43, [\"city\", \"educ\", \"exper\", \"nwifeinc\", \"kidslt6\", \"kidsge6\"]])\n",
    "y = mroz.loc[mroz.age <= 43, 'lwage']\n",
    "\n",
    "model = sm.OLS(y, X, hasconst=True)\n",
    "results = model.fit()\n",
    "\n",
    "# Somme des carrés des residus pour ce groupe \n",
    "SSE1 = np.sum(results.resid**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aac43a",
   "metadata": {},
   "source": [
    "3. Regression pour le groupe dont l'âge est $> 43$ ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de89c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(mroz.loc[mroz.age > 43, [\"city\", \"educ\", \"exper\", \"nwifeinc\", \"kidslt6\", \"kidsge6\"]])\n",
    "y = mroz.loc[mroz.age > 43, 'lwage']\n",
    "\n",
    "model = sm.OLS(y, X, hasconst=True)\n",
    "resultats = model.fit()\n",
    "\n",
    "# Somme des carrés des residus pour ce groupe \n",
    "SSE2 = np.sum(resultats.resid**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b58779",
   "metadata": {},
   "source": [
    "Calcul de la statistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat = ((SSE_ens-(SSE1+SSE2)) / p)  / ((SSE1+SSE2)/(n-2*p))\n",
    "p_value = stats.f.sf(f_stat, p, n-2*p)                   \n",
    "    \n",
    "pd.DataFrame({\"f-stat\": f_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43aedd",
   "metadata": {},
   "source": [
    "On ne rejette pas l'hypothèse nulle. Il n'ya donc pas de changement de structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dc9b9",
   "metadata": {},
   "source": [
    "###### 16. Ajouter au modèle de la question 7 la variable huseduc. Faire ensuite la même régression en décomposant la variable huseduc en 4 variables binaires construites selon votre choix. Faire le test de non significativité de l’ensemble des variables binaires. Donnez les p-valeurs et commentez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc51b3",
   "metadata": {},
   "source": [
    "##### a. Ajouter au modèle de la question 7 la variable huseduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04427c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mroz['lwage']\n",
    "s = np.shape(df['wage'])\n",
    "constante = np.ones(s)\n",
    "X = sm.add_constant(mroz[['city', 'educ', 'exper', 'nwifeinc', 'kidslt6', 'kidsge6','huseduc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= sm.OLS(y,X)\n",
    "resultats=model.fit()\n",
    "print(resultats.summary())\n",
    "u=resultats.resid\n",
    "SSR0=u.T@u\n",
    "print(SSR0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1f20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e4518a2",
   "metadata": {},
   "source": [
    " ###### b. Faire ensuite la même régression en décomposant la variable huseduc en 4 variables binaires construites selon votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Décomposition de la variable 'huseduc' en 4 variables binaires selon ses quartiles\n",
    "quartiles = [np.percentile(mroz['huseduc'],q) for q in [0, 25, 50, 75, 100]]\n",
    "\n",
    "masks = np.empty((mroz.shape[0], 4))\n",
    "for i in range(len(quartiles)-1):\n",
    "    masks[:, i] = (mroz[\"huseduc\"]>=quartiles[i]) & (mroz[\"huseduc\"]<quartiles[i+1])\n",
    "\n",
    "huseduc_decompose = pd.DataFrame(data=masks, columns=[\"huseduc_0_25\", \"huseduc_25_50\", \"huseduc_50_75\",\n",
    "                                                   \"huseduc_75_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "df1=mroz[[\"city\", \"educ\", \"exper\", \"nwifeinc\", \"kidslt6\", \"kidsge6\"]].reset_index()\n",
    "df1=df1.drop('index', axis=1)\n",
    "X = sm.add_constant(pd.concat([df1,huseduc_decompose],ignore_index=False,axis=1))\n",
    "\n",
    "y = mroz[\"lwage\"].reset_index().drop('index', axis=1)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "residual = resultats.resid\n",
    "print(resultats.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14188a",
   "metadata": {},
   "source": [
    "##### c.  Faire le test de non significativité de l’ensemble des variables binaires. Donnez les p-valeurs et commentez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca18d6f",
   "metadata": {},
   "source": [
    "La statistique de Fisher associé  est:\n",
    "\n",
    "$f_{stat} = \\frac{\\frac{SSE_1-SSE}{4}}{\\frac{SSE}{n-p-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèle sans contrainte\n",
    "df1=mroz[[\"city\", \"educ\", \"exper\", \"nwifeinc\", \"kidslt6\", \"kidsge6\"]].reset_index()\n",
    "df1=df1.drop('index', axis=1)\n",
    "X = sm.add_constant(pd.concat([df1,huseduc_decompose],ignore_index=False,axis=1))\n",
    "\n",
    "y = mroz[\"lwage\"].reset_index().drop('index', axis=1)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "resultats = model.fit()\n",
    "residual = resultats.resid\n",
    "SSE = np.sum(residual**2)\n",
    "\n",
    "#Modèle contraint\n",
    "X = sm.add_constant(df1)\n",
    "y = mroz[\"lwage\"].reset_index().drop('index', axis=1)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "residual = results.resid\n",
    "\n",
    "SSE1 = np.sum(residual**2)\n",
    "\n",
    "\n",
    "# --- Compute Fisher Stat --- #\n",
    "\n",
    "f_stat = ((SSE1 - SSE) / 4)  /  (SSE / (n - p))\n",
    "p_value = stats.f.sf(f_stat, 4, n - p)\n",
    "\n",
    "pd.DataFrame({\"f-stat\": f_stat, \"p-value\": p_value}, index=[\"results\"])\\\n",
    "               .style.format({'f-stat': \"{:.3f}\", 'p-value': \"{:.3f}\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60e389",
   "metadata": {},
   "source": [
    "On ne peut alors pas rejeter l'hypothèse de non significativité de l'ensemble des  variables binaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff9e54",
   "metadata": {},
   "source": [
    "<h1><center>Partie 2: Séries temporelles </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08ba9c",
   "metadata": {},
   "source": [
    "##### 1. Importer les données du fichier quarterly.xls (corriger le problème éventuel d’observations manquantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1436aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('quarterly.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f28188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fe725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification de valeurs manquantes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e5210",
   "metadata": {},
   "source": [
    "##### 2. Stationnariser la série de CPI en utilisant la méthode de régression qui inclue un terme de tendance dont la forme fonctionnelle est à choisir (linéaire, quadratique, log, exponentielle, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10703a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "plt.plot(df[\"DATE\"], df[\"CPI\"])\n",
    "plt.xticks([x for i, x in enumerate(df[\"DATE\"]) if i%10==0], rotation=90)\n",
    "plt.title(\"Evolution du CPI au cours du temps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = np.arange(1, len(df)+1)\n",
    "y = df[\"CPI\"]\n",
    "func_type = [\"linéaire\", \"quadratique\", \"log\", \"exp\"]\n",
    "X_list = [X, np.column_stack((X, X**2)), np.log(X), np.exp(X)]\n",
    "\n",
    "fig, axes = plt.subplots(len(func_type), 2, figsize=(15, 15))\n",
    "all_preds = []\n",
    "\n",
    "for i, X in enumerate(X_list):\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    preds = model.predict(results.params)\n",
    "    all_preds.append(preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    axes[i, 0].plot(y, label=\"CPI\")\n",
    "    axes[i, 0].plot(preds, label=\"prédictions\")\n",
    "    axes[i, 0].set_title(f\"Fit du modèle {func_type[i]} (RMSE: {rmse:.1f})\")\n",
    "    axes[i, 0].legend()\n",
    "    axes[i, 1].plot(results.resid)\n",
    "    axes[i, 1].set_title(f\"Résidu du modèle {func_type[i]}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a5668",
   "metadata": {},
   "source": [
    "La méthode de regression avec la tendance quadratique semble la mieux adaptée (RMSE plus petite)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b535ad",
   "metadata": {},
   "source": [
    "##### 3. Stationnariser la série de CPI en utilisant un moyenne mobile centrée 5x5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91812021",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([1/25, 2/25, 3/25, 4/25, 5/25, 4/25, 3/25, 2/25, 1/25])\n",
    "df.loc[:, \"CPI_rollmean\"] = df[\"CPI\"].rolling(9, center=True).apply(lambda x: np.sum(weights*x))\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.plot(df[\"DATE\"], df[\"CPI\"] - df[\"CPI_rollmean\"])\n",
    "plt.xticks([x for i, x in enumerate(df[\"DATE\"]) if i%10==0], rotation=90)\n",
    "plt.title(\"CPI stationarisé par moyenne mobile centrée 5x5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b0e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab28f58c",
   "metadata": {},
   "source": [
    "##### 4. Calculer inf, le taux d’inflation à partir de la variable CPI. Faire un graphique dans le temps de inf. Commentez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3872e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"inf\"] = df[\"CPI\"] / df[\"CPI\"].shift(1) - 1\n",
    "plt.figure(figsize=(11, 5))\n",
    "plt.plot(df[\"DATE\"], df[\"inf\"])\n",
    "plt.title(\"Evolution de l'inflation au cours du temps\")\n",
    "plt.xticks([x for i, x in enumerate(df[\"DATE\"]) if i%10==0], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1e3fa",
   "metadata": {},
   "source": [
    "#### 5. Interpréter l'autocorrélogramme et l'autocorrélogrammes partiels de inf. Quelle est la différence entre ces deux graphiques ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "inf = df[\"inf\"].dropna()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,5))\n",
    "plot_acf(inf, ax=axes[0], zero=False, title=\"Autocorrelation de la série 'inf'\")\n",
    "plot_pacf(inf, ax=axes[1], zero=False, title=\"Autocorrelation partielle de la série 'inf'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788191c",
   "metadata": {},
   "source": [
    "* Autocorrelation d'ordre $h$ : $\\rho(h) = \\frac{\\gamma(h)}{\\gamma(0)}$ avec $\\gamma(h) = \\text{cov}(Y_t, Y_{t+h})$\n",
    "* Autocorrelations partielles = coéfficients de la regression linéaire sur les lags considérés (ici 25) pour prédire la valeur au temp $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236fb74",
   "metadata": {},
   "source": [
    "##### 6. Quelle est la différence entre la stationnarité et l'ergodicité ? Pourquoi a-t-on besoin de ces deux conditions. Expliquez le terme \"spurious regression\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2013e",
   "metadata": {},
   "source": [
    "* Stationarité stricte : la distribution jointe de $(Y_{t+1}, Y_{t+2},\\cdots, Y_{t+h})$ ne dépend pas de $h$, ie le passé et le futur se ressemblent.\n",
    "* Stationarité faible : $\\forall t, \\mathbb{E}[Y_t] = \\mu$ et $\\forall t, \\forall h, \\text{cov}(Y_t, Y_{t+h}) = \\gamma(h)$\n",
    "* Ergodicité : $\\underset{h \\rightarrow \\infty}{\\lim} \\rho(h) = 0$, ie le processus oublie les conditions initiales\n",
    "\n",
    "Ces deux conditions sont nécessaires car elles permettent, pour la première, d'appliquer le Théorème Central Limite et pour la seconde, de faire correspondre la moyenne temporelle et la moyenne spatiale (Théorème ergodique) et ainsi analyser le processus en analysant une seule trajectoire.\n",
    "\n",
    "*Spurious Regresion* : corrélation n'est pas causation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3d930",
   "metadata": {},
   "source": [
    "##### 7. Faire le test Augmented Dickey Fuller pour inf en utilisant utilisant le critère AIC pour déterminer le nombre de lags à inclure. Commenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adf_results = adfuller(inf, autolag=\"AIC\")\n",
    "\n",
    "print(f\"ADF Stat : {adf_results[0]:.3f}, p-value : {adf_results[1]:.3e}\")\n",
    "print(f\"Nombre de lags utilisés : {adf_results[2]}\")\n",
    "print(\"Valeurs critiques :\")\n",
    "for k, v in adf_results[4].items():\n",
    "    print(f\"    [{k} : {v:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce76f7",
   "metadata": {},
   "source": [
    "La p-value est inférieure à 5%, on peut donc rejeter l'hypothèse nulle qui est que la série n'est pas stationaire. La série est donc stationaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb97848",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_results = adfuller(df[\"CPI\"], regression=\"ctt\", autolag=\"AIC\")\n",
    "\n",
    "print(f\"ADF Stat : {adf_results[0]:.3f}, p-value : {adf_results[1]:.3e}\")\n",
    "print(f\"Nombre de lags utilisés : {adf_results[2]}\")\n",
    "print(\"Valeurs critiques :\")\n",
    "for k, v in adf_results[4].items():\n",
    "    print(f\"    [{k} : {v:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad153d",
   "metadata": {},
   "source": [
    "##### 8. Proposer une modélisation AR(p) de inf, en utilisant tous les outils vus au cours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import ARIMA\n",
    "\n",
    "# modèle ARIMA(p,0,0) = AR(p)\n",
    "ar = ARIMA((2,0,0))\n",
    "\n",
    "ar.fit(df[\"inf\"])\n",
    "preds = ar.predict_in_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 5))\n",
    "plt.plot(df[\"DATE\"], df[\"inf\"], label=\"inf\")\n",
    "plt.plot(df[\"DATE\"], preds, label=\"AR(2)\")\n",
    "plt.title(\"Inflation et predictions du modèle AR(2)\")\n",
    "plt.legend()\n",
    "plt.xticks([x for i, x in enumerate(df[\"DATE\"]) if i%10==0], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b804c",
   "metadata": {},
   "source": [
    "##### 9. Estimer le modèle de la courbe de Philips qui explique le taux de chômage (Unemp) en fonction du taux d’inflation courant et une constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf389cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on passe la variable `Unemp` à la même échelle que `inf`\n",
    "df.loc[:, \"Unemp\"] = df[\"Unemp\"] / 100\n",
    "X9 = inf\n",
    "y9 = df[\"Unemp\"].iloc[1:]\n",
    "X9 = sm.add_constant(X9)\n",
    "model9 = sm.OLS(y9, X9)\n",
    "results9 = model9.fit()\n",
    "preds = model9.predict(results9.params, X9)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(inf, y9)\n",
    "plt.plot(inf, preds, color=\"C1\", label=\"regression line\")\n",
    "plt.title(\"Courbe de Philips\")\n",
    "plt.xlabel(\"Inflation rate\")\n",
    "plt.ylabel(\"Unemployment rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9641f61",
   "metadata": {},
   "source": [
    "##### 10. Tester l’autocorrélation des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c353e32",
   "metadata": {},
   "source": [
    "Pour tester l'autocorrélation des erreurs, on définit le modèle autorégressif suivant : $u_t = \\rho u_{t-1} + \\epsilon$ où $u_t$ est le résidu au temps $t$.\n",
    "\n",
    "On teste l'hypothèse $H_0 : \\rho = 0$ avec un test de Student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba44bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = results9.resid.iloc[1:]\n",
    "X10 = results9.resid.shift(1).iloc[1:]\n",
    "\n",
    "model10 = sm.OLS(u, X10)\n",
    "results10 = model10.fit()\n",
    "print(results10.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f410c8",
   "metadata": {},
   "source": [
    "Comme indiqué dans le résumé du modèle OLS de *statsmodels*, la p-valeur du test de Student pour le coéfficient du modèle est 0.000 donc on peut rejeter l'hypothèse nulle à 1%. Les erreurs sont autocorrélées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a3250",
   "metadata": {},
   "source": [
    "##### 11. Corriger l’autocorrélation des erreurs par la méthode vue en cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a19415",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = results10.params[0]\n",
    "y11 = df[\"Unemp\"] - rho * df[\"Unemp\"].shift(1)\n",
    "y11 = y11.iloc[2:]\n",
    "X11 = df[\"inf\"] - rho * df[\"inf\"].shift(1)\n",
    "X11 = X11.iloc[2:]\n",
    "X11 = sm.add_constant(X11)\n",
    "\n",
    "model11 = sm.OLS(y11, X11)\n",
    "results11 = model11.fit()\n",
    "print(results11.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b97c51",
   "metadata": {},
   "source": [
    "##### 12. Tester la stabilité de la relation chômage-inflation sur deux sous-périodes de taille identique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142140b",
   "metadata": {},
   "source": [
    "Il s'agit de réaliser un Test de Chow:\n",
    "* Modèle contraint : régression sur l'ensemble de la période -> $SSR1$\n",
    "* 2 modèles non-contraints : régressions sur les sous-périodes -> $SSR0_{total} = SSR0_1 + SSR0_2$.\n",
    "\n",
    "* L'hypothèse nulle $H_0$ est que les coéfficients de régression des 3 modèles sont les mêmes.\n",
    "\n",
    "* On calcul la statistique de Fisher : $F = \\frac{(SSR0_{total} - SSR1) / c}{ SSR0_{total} / ddl}$\n",
    "avec $ddl = n-2(p+1)$ et restrictions : $c = p + 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "def calc_ssr(X, y):\n",
    "    \"\"\"\n",
    "    Caclul de la somme des résidus au carré\n",
    "    \"\"\"\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    u = model.resid\n",
    "    SSR = u.T @ u\n",
    "    return SSR\n",
    "\n",
    "def calc_fisher(SSR0, SSR1, c, ddl):\n",
    "    \"\"\"\n",
    "    Calcul de la statistique de Fisher avec `c` nombre de contraintes\n",
    "    et `ddl` nombre de degrés de liberté du modèle non contraint\n",
    "    \"\"\"\n",
    "    F = ((SSR1 - SSR0)/c) / (SSR0/ddl)\n",
    "    p_val = f.sf(F, c, ddl)\n",
    "    print(f\"F-stat : {F:.3f}, p-value : {p_val:.2e}\")\n",
    "    return F, p_val\n",
    "\n",
    "def fisher_test(X, y, constrained_cols, q):\n",
    "    \"\"\"\n",
    "    Test de Fisher avec contrainte sur les variables `constrained_cols`\n",
    "    et niveau de confiance `q`.\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    # on calcule la somme des carrés des résidus du modèle non contraint\n",
    "    SSR0 = calc_ssr(X, y)\n",
    "    # colonnes du modèle contraint\n",
    "    new_cols = list(set(X.columns) - set(constrained_cols))\n",
    "    # modèle contraint\n",
    "    X1 = X.loc[:, new_cols]\n",
    "    SSR1 = calc_ssr(X1, y)\n",
    "    c = len(constrained_cols) # nombre de contraintes\n",
    "    ddl = n - p # dégrés de liberté\n",
    "    # Stat de Fisher\n",
    "    F, p_val = calc_fisher(SSR0, SSR1, c, ddl)\n",
    "    perc = f.ppf(q, c, ddl)\n",
    "    if perc < F:\n",
    "        print(f\"Avec seuil de significativité de {(1-q)*100:.2f}%, on rejette H0\")\n",
    "    else:\n",
    "        print(f\"Avec seuil de significativité de {(1-q)*100:.2f}%, on ne rejette pas H0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chow_test(X, y):\n",
    "    # modèle contraint\n",
    "    model1 = sm.OLS(y, X).fit()\n",
    "    SSR1 = model1.resid.T @ model1.resid\n",
    "    # point de split du dataset en 2 parts égales\n",
    "    split_point = X.shape[0] // 2\n",
    "    X1 = X.iloc[:split_point]\n",
    "    y1 = y.iloc[:split_point]\n",
    "    X2 = X.iloc[split_point:]\n",
    "    y2 = y.iloc[split_point:]\n",
    "    # résidus des 2 sous-modèles non-contraints \n",
    "    SSR0_1 = calc_ssr(X1, y1)\n",
    "    SSR0_2 = calc_ssr(X2, y2)\n",
    "    # nombre de restrictions:\n",
    "    c = X.shape[1]\n",
    "    ddl = X.shape[0] - 2 * c\n",
    "    # stat de Fisher et p-value\n",
    "    F, p_val = calc_fisher(SSR0_1+SSR0_2, SSR1, c, ddl)\n",
    "    if p_val < 0.05:\n",
    "        print(\"On rejette l'hypothèse de stabilité de la relation chômage-inflation à 5%\")\n",
    "    else:\n",
    "        print(\"On ne rejette par l'hypothèse nulle à 5%\")\n",
    "    return F, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en repartant du modèle de la question 11\n",
    "_ = chow_test(X11, y11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9203981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en repartant du modèle de la question 9\n",
    "_ = chow_test(X9, y9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c17c6",
   "metadata": {},
   "source": [
    "##### 13. Estimer la courbe de Philips en supprimant l'inflation courante des variables explicatives mais en ajoutant les délais d’ordre 1, 2, 3 et 4 de l’inflation et du chômage. Faire le test de Granger de non causalité de l’inflation sur le chômage. Donnez la p-valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a387919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X13 = df[[\"inf\", \"Unemp\"]]\n",
    "X13 = pd.concat([X13.shift(i) for i in range(1,5)], axis=1).iloc[5:]\n",
    "cols = []\n",
    "for i in range(1,5):\n",
    "    cols.append(f\"inf_{i}\")\n",
    "    cols.append(f\"Unemp_{i}\")\n",
    "X13.columns = cols\n",
    "X13 = sm.add_constant(X13)\n",
    "\n",
    "y13 = df[\"Unemp\"].iloc[5:]\n",
    "\n",
    "X13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model13 = sm.OLS(y13, X13)\n",
    "results13 = model13.fit()\n",
    "preds = model13.predict(results13.params, X13)\n",
    "print(\"Coéfficients de régression:\\n\",results13.params)\n",
    "\n",
    "plt.figure(figsize=(11,5))\n",
    "plt.plot(df[\"DATE\"].iloc[5:], y13, label=\"ground truth\")\n",
    "plt.plot(df[\"DATE\"].iloc[5:], preds, color=\"C1\", label=\"predictions\")\n",
    "plt.title(\"Estimation du taux de chômage via la courbe de Philips\")\n",
    "#plt.xlabel(\"\")\n",
    "plt.ylabel(\"Unemployment rate\")\n",
    "plt.xticks([x for i, x in enumerate(df[\"DATE\"]) if i%10==0], rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d88a94",
   "metadata": {},
   "source": [
    "On réalise le test de Granger. Il s'agit d'un test de Fisher avec pour paramètres :\n",
    "* $H_0$ : les variables liées à l'inflation ne sont pas significatives pour le modèle (ie non causalité de l'inflation sur le chômage)\n",
    "* modèle non contraint : on prend en compte toutes les variables\n",
    "* modèle contraint : on retire les variables liées à l'inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_test(X13, y13, [f\"inf_{i}\" for i in range(1,5)], 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa2db2",
   "metadata": {},
   "source": [
    "##### 14. Représentez graphiquement les délais distribués et commentez. Calculer l’impact à long de terme de l’inflation sur le chômage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_coef = [results13.params[f\"inf_{i}\"] for i in range(1,5)]\n",
    "inf_tick = [col for col in X13.columns if \"inf\" in col]\n",
    "unemp_coef = [results13.params[f\"Unemp_{i}\"] for i in range(1,5)]\n",
    "unemp_tick = [col for col in X13.columns if \"Unemp\" in col]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(11,4))\n",
    "axes[0].stem(inf_tick, inf_coef)\n",
    "axes[0].set_xticklabels(inf_tick)\n",
    "axes[0].set_title(\"Délais distribués de la variable inf\")\n",
    "\n",
    "axes[1].stem(unemp_tick, unemp_coef)\n",
    "axes[1].set_xticklabels(unemp_tick)\n",
    "axes[1].set_title(\"Délais distribués de la variable Unemp\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7d493",
   "metadata": {},
   "source": [
    "Pour le modèle,\n",
    "$$\n",
    "y_t = \\beta_0 + \\sum_{k=1}^{4} \\beta_k y_{t-k} + \\sum_{j=1}^{4}\\alpha_j x_{t-j} + u_t\n",
    "$$\n",
    "le coéfficient long-terme de $x$ sur $y$ est : $$\\theta = \\frac{\\sum_{j=1}^4 \\alpha_j}{1 - \\sum_{k=1}^4 \\beta_k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.sum(inf_coef) / (1- np.sum(unemp_coef))\n",
    "\n",
    "print(f\"Coéfficient long terme de l'inflation sur le chômage: {theta:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
